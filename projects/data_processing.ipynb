{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xd_FuPXGVPtc"
   },
   "source": [
    "# Example how to visualize the data. This should hopefully help you understand the form of the data\n",
    "## Other important information about the extracted features of the data can be found in the features_info.txt and features.txt files in the UCI_HAR folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kyjjdhKdVPtc",
    "outputId": "20af4aab-4a9b-4141-8fea-aa7e59e89aea"
   },
   "outputs": [],
   "source": [
    "# Import Necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import sklearn as sk\n",
    "import sys\n",
    "print('Your python version: {}'.format(sys.version_info.major))\n",
    "\n",
    "\n",
    "\n",
    "#Path to the dataset folder\n",
    "filepath='./UCI_HAR/'\n",
    "\n",
    "groups=['train','test']\n",
    "\n",
    "for group in groups:\n",
    "    prefix=filepath+group+'/InertialSignals/'\n",
    "    \n",
    "    \n",
    "    filenames = list()\n",
    "    filenames += ['body_acc_x_'+group+'.txt', 'body_acc_y_'+group+'.txt', 'body_acc_z_'+group+'.txt']\n",
    "    filenames += ['body_gyro_x_'+group+'.txt', 'body_gyro_y_'+group+'.txt', 'body_gyro_z_'+group+'.txt']\n",
    "\n",
    "    loaded = []\n",
    "    for name in filenames:\n",
    "        file=open(prefix+name,'r')\n",
    "        data = []\n",
    "        for x in file:\n",
    "            data.append([float(ts) for ts in x.split()])\n",
    "        data = np.array(data)\n",
    "        #Concatenation of all data concerning the two 3D raw features (body acceleration and angular velocity)\n",
    "        loaded.append(data)\n",
    "\n",
    "    #Name of the last 3D raw feature\n",
    "    filenames_rest = ['total_acc_x_'+group+'.txt', 'total_acc_y_'+group+'.txt', 'total_acc_z_'+group+'.txt']\n",
    "\n",
    "    #First add the two previous 3D raw features\n",
    "    loaded_all = []\n",
    "    loaded_all += loaded\n",
    "\n",
    "    #Then add the last 3D raw feature\n",
    "    for name in filenames_rest:\n",
    "        file=open(prefix+name,'r')\n",
    "        data = []\n",
    "        for x in file:\n",
    "            data.append([float(ts) for ts in x.split()])\n",
    "        data = np.array(data)\n",
    "        #Concatenation of all data concerning all 3D raw features (body acceleration, angular velocity and total acceleration)\n",
    "        loaded_all.append(data)\n",
    "\n",
    "    # Stack group so that features are the 3rd dimension --> (samples, time steps, features)\n",
    "    loaded = np.dstack(loaded)\n",
    "    loaded_all = np.dstack(loaded_all)\n",
    "\n",
    "    if group == 'train':\n",
    "        #Training set for two 3D raw features\n",
    "        tx_train = loaded\n",
    "        #Training set for all 3D raw features\n",
    "        tx_train_all = loaded_all\n",
    "    if group =='test':\n",
    "        #Testing set for two 3D raw features\n",
    "        tx_test = loaded\n",
    "        #Testing set for all 3D raw features\n",
    "        tx_test_all = loaded_all\n",
    "\n",
    "nbTimeseries = tx_train_all[0].shape[1]\n",
    "lengthTimeseries = tx_train_all[0].shape[0]\n",
    "print(\"Shape of examples:\",tx_train_all[0].shape,\" (i.e. \",nbTimeseries,\" timeseries of length=\",lengthTimeseries,\")\")\n",
    "\n",
    "print(\"Training set shape:\",tx_train_all.shape)\n",
    "print(\"Test set shape:\",tx_test_all.shape)\n",
    "\n",
    "# Load labels\n",
    "y_train = []\n",
    "y_test = []\n",
    "y_train_file = open(filepath+'train/y_train.txt', 'r')\n",
    "y_test_file = open(filepath+'test/y_test.txt', 'r')\n",
    "for y in y_train_file:\n",
    "    y_train.append(int(y.rstrip('\\n')))\n",
    "for y in y_test_file:\n",
    "    y_test.append(int(y.rstrip('\\n')))\n",
    "target_train = np.array(y_train) - 1\n",
    "target_test = np.array(y_test) - 1\n",
    "\n",
    "# Mapping table for classes\n",
    "labels = {1:'WALKING', 2:'WALKING UPSTAIRS', 3:'WALKING DOWNSTAIRS',\n",
    "          4:'SITTING', 5:'STANDING', 6:'LAYING'}\n",
    "\n",
    "nbClasses = len(labels)\n",
    "print(\"Number of classes =\", nbClasses)\n",
    "print(\"Activity classes (target values)\",labels)\n",
    "\n",
    "# Shuffle (because data is initially somewhat organized by class)\n",
    "tx_train_all, target_train = sk.utils.shuffle(tx_train_all, target_train, random_state=0)\n",
    "tx_test_all, target_test = sk.utils.shuffle(tx_test_all, target_test, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AuETgHoIVPtd",
    "outputId": "3ece2993-18d8-48b7-f548-710b329e7326"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ex0 = tx_train_all[0].T # Transpose (for selection of body_acc variables)\n",
    "ex0_body_acc = np.array([ex0[0] , ex0[1], ex0[2]])\n",
    "ex0_body_acc = ex0_body_acc.T # Transpose back (for plotting)\n",
    "ex0_body_gyro = np.array([ex0[3] , ex0[4], ex0[5]])\n",
    "ex0_body_gyro = ex0_body_gyro.T # Transpose back (for plotting)\n",
    "print(\"\\n body acceleration [ba_x, ba_y, ba_z]=f(time) for example #0\")\n",
    "plt.plot(ex0_body_acc)\n",
    "plt.show()\n",
    "\n",
    "ex1 = tx_train_all[1].T # Transpose (for selection of body_acc variables))\n",
    "ex1_body_acc = np.array([ex1[0] , ex1[1], ex1[2]])\n",
    "ex1_body_acc = ex1_body_acc.T # Transpose back (for plotting)\n",
    "ex1_body_gyro = np.array([ex1[3] , ex1[4], ex1[5]])\n",
    "ex1_body_gyro = ex1_body_gyro.T # Transpose back (for plotting)\n",
    "print(\"\\n body acceleration [ba_x, ba_y, ba_z]=f(time) for example #1\")\n",
    "plt.plot(ex1_body_acc)\n",
    "plt.show()\n",
    "\n",
    "ex160 = tx_train_all[160].T # Transpose (for selection of body_acc variables))\n",
    "ex160_body_acc = np.array([ex160[0] , ex160[1], ex160[2]])\n",
    "ex160_body_acc = ex160_body_acc.T # Transpose back (for plotting)\n",
    "ex160_body_gyro = np.array([ex160[3] , ex160[4], ex160[5]])\n",
    "ex160_body_gyro = ex160_body_gyro.T # Transpose back (for plotting)\n",
    "print(\"\\n body acceleration [ba_x, ba_y, ba_z]=f(time) for example #160\")\n",
    "plt.plot(ex160_body_acc)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n body_gyro [bg_x, bg_y, bg_z]=f(time) for example #0\")\n",
    "plt.plot(ex0_body_gyro)\n",
    "plt.show()\n",
    "print(\"\\n body_gyro [bg_x, bg_y, bg_z]=f(time) for example #1\")\n",
    "plt.plot(ex1_body_gyro)\n",
    "plt.show()\n",
    "print(\"\\n body_gyro [bg_x, bg_y, bg_z]=f(time) for example #160\")\n",
    "plt.plot(ex160_body_gyro)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n ALL 9 channels of example #0 which has classID=\"+labels[target_train[0]+1])\n",
    "plt.plot(tx_train_all[0])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n ALL 9 channels of example #1 which has classID=\"+labels[target_train[1]+1])\n",
    "plt.plot(tx_train_all[1])\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n ALL 9 channels of example #160 which has classID=\"+labels[target_train[160]+1])\n",
    "plt.plot(tx_train_all[160])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
