{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d80ebb4",
   "metadata": {},
   "source": [
    "# Outlier Detection in Human Activity Data\n",
    "\n",
    "In this project you will be performing outlier detection on the UCI Human Activity Recognition (HAR) dataset, focusing on two types of outliers:\n",
    "- Instances far from the center of the class distribution.\n",
    "- Instances that are isolated in feature space.\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Data Preprocessing: Load and prepare the UCI HAR dataset for classification.\n",
    "- Feature Extraction: Train a network (e.g., a neural network or another feature extractor) to classify the activities and extract useful features.\n",
    "- Modeling Class Distributions: Use the extracted features to model the distribution of each class using a Gaussian Mixture Model (GMM).\n",
    "- Center Detection: Identify the center of the distribution for each class and apply k-Nearest Neighbors (kNN) to find the central instances and prototypes for each class.\n",
    "- Outlier Detection: For each class, identify outliers using:\n",
    "    - Instances far from the center.\n",
    "    - Instances that are isolated in the feature space.\n",
    "- Comparison: Compare instances close to the center and the detected outliers. Attempt to form hypotheses explaining why the outliers are different.\n",
    "- Global Outlier Detection: Repeat the outlier detection for the entire dataset (ignoring class labels), and compare the results to the class-specific outliers.\n",
    "\n",
    "**Important**: At the end you should write a report of adequate size, which will probably mean at least half a page. In the report you should describe how you approached the task. You should describe:\n",
    "- Encountered difficulties (due to the method, e.g. \"not enough training samples to converge\", not technical like \"I could not install a package over pip\")\n",
    "- Steps taken to alleviate difficulties\n",
    "- General description of what you did, explain how you understood the task and what you did to solve it in general language, no code.\n",
    "- Potential limitations of your approach, what could be issues, how could this be hard on different data or with slightly different conditions\n",
    "- If you have an idea how this could be extended in an interesting way, describe it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ebb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "def unzip(filename, dest_path = None):\n",
    "    # unzips a zip file in the folder of the notebook to the notebook\n",
    "    with ZipFile(filename, 'r') as zObject: \n",
    "        # Extracting all the members of the zip  \n",
    "        # into a specific location. a\n",
    "        if dest_path is None:\n",
    "            zObject.extractall(path=os.getcwd())\n",
    "        else:\n",
    "            zObject.extractall(path=dest_path)\n",
    "\n",
    "import os\n",
    "def download(url, filename):\n",
    "    # download with check if file exists already\n",
    "    if os.path.isfile(filename):\n",
    "        return\n",
    "    urllib.request.urlretrieve(url,filename)\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Un-comment lines below only if executing on Google-COLAB\n",
    "# ![[ -f UCI_HAR.zip ]] || wget --no-check-certificate https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/Practical_sequentialData/UCI_HAR.zip\n",
    "# ![[ -f \"UCI_HAR\" ]] || unzip UCI_HAR.zip\n",
    "\n",
    "download('https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/Practical_sequentialData/UCI_HAR.zip','UCI_HAR.zip')\n",
    "\n",
    "unzip('UCI_HAR.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d8208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and Standardize Data\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load train and test data\n",
    "train_data = pd.read_csv('./UCI_HAR/train/X_train.txt', delim_whitespace=True, header=None)\n",
    "train_labels = pd.read_csv('./UCI_HAR/train/y_train.txt', delim_whitespace=True, header=None)\n",
    "test_data = pd.read_csv('./UCI_HAR/test/X_test.txt', delim_whitespace=True, header=None)\n",
    "test_labels = pd.read_csv('./UCI_HAR/test/y_test.txt', delim_whitespace=True, header=None)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data)\n",
    "test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "# Create a custom dataset class for PyTorch\n",
    "from torch.utils.data import Dataset\n",
    "class HARDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels - 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02783097",
   "metadata": {},
   "source": [
    "### Step 3: Feature Extraction\n",
    "Define a feature extraction model (e.g., an LSTM-based network).\n",
    "\n",
    "You should:\n",
    "- Design a model architecture.\n",
    "- Train the model on the training data.\n",
    "- Save extracted features for further analysis.\n",
    "\n",
    "Provide training logic, loss computation, and optimization steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ecf6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the feature extraction model here\n",
    "# Suggested tools: PyTorch, torch.nn.LSTM, torch.optim\n",
    "# Extract and save features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55a5b0e",
   "metadata": {},
   "source": [
    "### Step 4: Modeling Class Distributions\n",
    "Use the extracted features to model class distributions with Gaussian Mixture Models (GMM).\n",
    "\n",
    "You should:\n",
    "- Fit a GMM for each class.\n",
    "- Store the GMMs for later outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300066c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement GMM fitting here\n",
    "# Suggested tool: sklearn.mixture.GaussianMixture\n",
    "# Fit GMMs for each class and store the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a42eed",
   "metadata": {},
   "source": [
    "### Step 5: Outlier Detection\n",
    "Using the GMMs, identify outliers in two ways:\n",
    "- Instances far from the center (low probability under the GMM).\n",
    "- Isolated instances using k-Nearest Neighbors (kNN).\n",
    "\n",
    "Provide detailed steps for each detection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5996187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement outlier detection logic here\n",
    "# Suggested tools: sklearn.neighbors.NearestNeighbors, numpy for thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455c284b",
   "metadata": {},
   "source": [
    "### Step 6: Visualization and Analysis\n",
    "Plot and compare central instances with detected outliers for each class.\n",
    "\n",
    "Discuss potential reasons for the differences between the central and outlier instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b746e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement visualization logic here\n",
    "# Suggested tools: matplotlib.pyplot for scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21823f6",
   "metadata": {},
   "source": [
    "### Step 7: Global Analysis\n",
    "Repeat the outlier detection process without considering class labels.\n",
    "\n",
    "Compare the results with class-specific outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement global outlier detection here\n",
    "# Fit a single GMM on all features and apply outlier detection logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a21e80",
   "metadata": {},
   "source": [
    "### Report Writing\n",
    "At the end of the notebook, provide a written report summarizing your approach, difficulties, and findings. Use Markdown to structure the report within the notebook itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base]",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
